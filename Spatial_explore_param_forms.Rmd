---
title: "Exploration of potential parametric forms of conditional extreme value models"
output: html_document
date: "2024-10-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(MASS)
library(tidyverse)
library(latex2exp)
library(viridis)
library(evd)
library(plgp)
library(gridExtra)
library(here)
library(tmap)
library(units)
library(RColorBrewer)
library(gnorm)
library(sf)
file.sources = list.files(pattern="*helpers.R")
sapply(file.sources,source,.GlobalEnv)
source("rotate_unrotate_coordinates.R")
gr_npole_lat <- 37.5
gr_npole_lon <- 177.5
load("spatialobjects.RData") # uk polygon and uk_temp_sf points sf objects
theme_set(theme_bw())
theme_replace(
  panel.spacing = unit(2, "lines"),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  strip.background = element_blank(),
  panel.border = element_rect(colour = "black", fill = NA) )
```

## Set-up

Currently, we work with 19 years of daily maximum temperature data over summer months (June, July, August). (The issue with year 20 remains unresolved, last year was removed.)

```{r, include=FALSE}
# UKCP 18 data (summer max daily temperatures 1999-2018) ----
ukcp18 <- readRDS("data/uk_1999_2018_summer.RDS") %>% relocate(dist_london,.after=dist_glasgow)
# remove last year of the data due to error (same data as first year)
ukcp18 <- ukcp18[,1:1716]

conv <- CnvRttPol(latlon = data.frame(long=ukcp18$Longitude,lat=ukcp18$Latitude),spol_coor = c(gr_npole_lon, gr_npole_lat))
uk_sf_rot <- data.frame(lon=conv$lon,lat=conv$lat,ind=conv$ind) %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326)
uk_sf_rot <- st_transform(uk_sf_rot,27700) %>% mutate(lon=conv$lon,lat=conv$lat)
# add buffer for calculating distance from the coast (distance from within the polygon sometimes causes error)
uk_buffered <- st_buffer(uk, 50000)   
# polygon of only the buffer
buffer_only <- st_difference(uk_buffered, uk) 
tm_shape(buffer_only) + tm_polygons()
coast_dist <- st_distance(uk_sf_rot,buffer_only)
uk_sf_rot <- cbind(uk_sf_rot,data.frame("coast_dist" = coast_dist))
tm_shape(uk_sf_rot) + tm_dots("coast_dist",size=1)
ukcp18 <- ukcp18 %>% mutate("Longitude_conv" = conv$lon, "Latitude_conv" = conv$lat, "coast_dist" = uk_sf_rot$coast_dist) %>% relocate(coast_dist,.before = dist_birmingham) %>% relocate(c(Longitude_conv,Latitude_conv),.before = is_location)
sims <- ukcp18 %>% dplyr::select(!contains("i")) %>% t() %>% as.data.frame()
# ordered alphabetically so Y1 Birmingham, Y2 Glasgow and Y3 is London
colnames(sims) <- paste0("Y",1:ncol(sims))
# transform to Laplace margins
sims <- as.data.frame((sims %>% apply(c(2),FUN=row_number))/(nrow(sims)+1)) %>% apply(c(1,2),FUN=unif_laplace_pit) %>% as.data.frame()
v <- 0.9 # set threshold
```
Add all sites together.
```{r}
Birmingham <- c(-1.9032,52.4806)
Glasgow <- c(-4.258109,55.859112)
London <- c(-0.127676,51.529972)
Inverness <- c(-4.22498,57.48065) # Inverness bus station
Lancaster <- c(-2.78440,54.00871) # PSC building Lancaster University
Newcastle <- c(-1.61682,54.96902) # Newcastle railway station
Cromer <- c(1.28486,53.05349)
Hull <- c(-0.335827,53.767750)
Lowestoft <- c(1.72431,52.48435)
Truro <- c(-5.05125342465549,50.263075821232704)
Dolgellau <- c(-3.8844362867080897,52.74213275545185)
Bournemouth <- c(-1.8650607066137428,50.72173094587856)
df_sites <- data.frame(Birmingham,Glasgow,London,Inverness,Lancaster,Newcastle,Cromer,Hull,Lowestoft,Truro,Dolgellau,Bournemouth)
```

## Follow-up from meeting with Simon: exploring $\alpha$ against distance

Recall the plot of marginal estimates of $\alpha$ parameter against distance[m] for the three conditioning sites. This is done using the sequential method (see below).

```{r, echo=FALSE}
# use parameteric form for a ----
# calculate distance from the 3 conditioning sites
# transform dataframe to include a vector of x (temperature) and d (distance from the conditioning site)
# p <- list()
# x <- list()
# d <- list()
# for (i in 1:3) {
#   cond_var <- find_site_index(as.numeric(df_sites[,i]))
# x[[i]] <- par_est(sims,v=0.9,given=c(cond_var),margin = "AGG", method="sequential")$a
# d[[i]] <- (ukcp18)[-cond_var,] %>% select(6+i) %>% pull() %>% units::drop_units()
# opt <- optim(par=c(0.01,0.1),fn=NLL_exp_norm_noise,x=x[[i]],d=d[[i]])
# # plot a function of alpha against distance
# a <- exp(-opt$par[1]*d[[i]])
# p[[i]] <- ggplot() + geom_line(data=data.frame(x=d[[i]],y=a),aes(x=x,y=y)) +
#   geom_point(data=data.frame(x=d[[i]],y=x[[i]]),aes(x=x,y=y)) +
#   ylab(TeX("$\\alpha$")) + xlab("Distance")
# }
# save(p,x,d,est_all_nokeef,file = "alphaspatial.RData")
load("alphaspatial.RData")
```

```{r}
grid.arrange(p[[1]],p[[2]],p[[3]],ncol=3)
```

We look at Birmingham (left) and London (right).

```{r}
# pick a straight line as a divide using 2 points: diff for each site 
is_above <- function(x,y,x1,x2,y1,y2) { y>(y2-y1)/(x2-x1)*(x-x1)+y1
}
plot_is_above <- function(x1,x2,y1,y2,cond_var) {
sites <- c("Birmingham", "Glasgow", "London")
df <- data.frame(x=d[[cond_var]],y=x[[cond_var]],z=as.character(is_above(d[[cond_var]],x[[cond_var]],x1=x1,x2=x2,y1=y1,y2=y2)))
p <- ggplot(df) + 
  geom_segment(x=x1,y=y1,xend=x2,yend=y2) +
   geom_point(aes(x=x,y=y,colour=factor(z))) + 
   ylab(TeX("$\\alpha$")) + xlab("Distance") + scale_color_manual(values = c("black", "#C11432")) + ggtitle(sites[cond_var])
return(p)
}
# plot to check Birmingham, Glasgow and London
p1 <- plot_is_above(x1=0,x2=450000,y1=1.2,y2=0.25,cond_var=1)
p2 <- plot_is_above(x1=0,x2=450000,y1=1.2,y2=0.25,cond_var=2)
p3 <- plot_is_above(x1=0,x2=450000,y1=1.2,y2=0.25,cond_var=3)
grid.arrange(p1,p2,p3,nrow=3)
```

Link both back to spatial locations to explore any potential patterns.

```{r, warning=FALSE}
map_is_above <- function(x1,x2,y1,y2,cond_var) {
  sites <- c("Birmingham", "Glasgow", "London")
  df <- data.frame(is_above = factor( as.character(is_above(d[[cond_var]],x[[cond_var]],x1=x1,x2=x2,y1=y1,y2=y2)))) %>%  add_row(.before=cond_var)
uk_tmp <- uk_temp_sf %>% dplyr::select() %>% cbind(ukcp18[,1:8]) %>% 
  arrange(is_location) 
tmp1 <- uk_tmp %>% cbind(df)
tm_shape(tmp1) + tm_dots(col="is_above",size=0.3,palette=c("TRUE" = "#C11432", "FALSE" = "black")) + tm_layout(main.title=sites[cond_var])
}
p1 <- map_is_above(x1=0,x2=450000,y1=1.2,y2=0.25,cond_var=1)
p2 <- map_is_above(x1=0,x2=450000,y1=1.2,y2=0.25,cond_var=2)
p3 <- map_is_above(x1=0,x2=450000,y1=1.2,y2=0.25,cond_var=3)
tmap_arrange(p1,p2,p3,ncol=3)
```

Birmingham and London show a similar pattern, which suggest higher dependence decay with distance (black) in the south of the mainland UK and in the vicinity of the conditioning sites. The dividing line could be moved to explore this result further.

## Sequential parameter estimation

1.  Fix $\beta=0$, estimate $\hat{\alpha}$.
2.  Fix $\alpha=\hat{\alpha}$, estimate $\hat{\beta}$.
3.  Fix $\alpha=\hat{\alpha}$ and $\beta=\hat{\beta}$, estimate $\hat{\mu}$ and $\hat{\sigma}$.
4.  Calculate observed residuals, estimate $\hat{\mu}_{AGG}$, $\hat{\sigma}_{AGG}$, $\hat{\delta}_l$ and $\hat{\delta}_u$.
```{r}
# est_all_nokeef <- data.frame("lik" = numeric(), "lika"= numeric(),"likb"= numeric(),"lik2"= numeric(),
#                           "a" = numeric(), "b" = numeric(),
#                           "mu" = numeric(),"mu_agg" = numeric(),
#                           "sig" = numeric(),"sig_agg" = numeric(),"sigl" = numeric(),"sigu" = numeric(),
#                           "delta" = numeric(),"deltal" = numeric(), "deltau" = numeric(),
#                           "given" = numeric(), "res" = numeric(), "cond_site" = character(), "tau" = character())
# for (i in 1:ncol(df_sites)) {
#     cond_site <- find_site_index(as.numeric(df_sites[,i]))
#     est_all_nokeef <- rbind(est_all_nokeef,par_est(df=sims,v=v,given=cond_site,margin = "AGGsigdelta", method="sequential2",keef_constraints = c(0)) %>% add_row(.before=cond_site) %>%  mutate(cond_site=names(df_sites[i]),tau=as.character(0)))
# }
# est_all_nokeef <- est_all_nokeef %>% mutate(cond_site= factor(cond_site,levels=names(df_sites)))
```


```{r, echo=FALSE}
# separate spatial estimates (no Keef constraints)
map_param(tmp_est = est_all_nokeef %>% filter(cond_site %in% names(df_sites)[1:3]),method = "AGG",facet_var = "cond_site")
```

Now, the same approach with alpha values on the fitted exponential curve with distance, so we use estimates of $\hat{\alpha}$ to fit an exponential curve to as a function of distance of site $i$ from the conditioning site $j$.

1.  Fix $\alpha=\alpha \left( d_{ij} \right) = \exp \left\{ - \phi d_{ij} \right\}$, estimate $\hat{\beta}$.
2.  Fix $\alpha=\alpha \left( d_{ij} \right)$ and $\beta=\hat{\beta}$, estimate $\hat{\mu}$ and $\hat{\sigma}$.
3.  Calculate observed residuals, estimate $\hat{\mu}_{AGG}$, $\hat{\sigma}_{AGG}$, $\hat{\delta}_l$ and $\hat{\delta}_u$.

```{r, echo=FALSE}
# plot parameter estimates against distance and on a map
# cond_var <- 1
# opt <- optim(par=c(0.01,0.1),fn=NLL_exp_norm_noise,x=x[[cond_var]],d=d[[cond_var]])
# tmp_est1a <- par_est(sims,v=v,given=c(cond_var),margin = "AGGsigdelta", method="sequential3", a=exp(-opt$par[1]*d[[cond_var]]))
# cond_var <- 2
# opt <- optim(par=c(0.01,0.1),fn=NLL_exp_norm_noise,x=x[[cond_var]],d=d[[cond_var]])
# tmp_est2a <- par_est(sims,v=v,given=c(cond_var),margin = "AGGsigdelta", method="sequential3", a=exp(-opt$par[1]*d[[cond_var]]))
# cond_var <- 3
# opt <- optim(par=c(0.01,0.1),fn=NLL_exp_norm_noise,x=x[[cond_var]],d=d[[cond_var]])
# tmp_est3a <- par_est(sims,v=v,given=c(cond_var),margin = "AGGsigdelta", method="sequential3",a=exp(-opt$par[1]*d[[cond_var]]))
# # save these objects for faster knitting
# save(uk,uk_temp_sf,tmp_est1,tmp_est2,tmp_est3,tmp_est1a,tmp_est2a,tmp_est3a,file = "spatialobjects.RData")
# index1 <- find_site_index(as.numeric(df_sites[,1]))
# index2 <- find_site_index(as.numeric(df_sites[,2]))
# index3 <- find_site_index(as.numeric(df_sites[,3]))
#                           
# tmp <- rbind(tmp_est1a %>%  add_row(.before=index1) %>% mutate("cond_site"=names(df_sites)[1]),tmp_est2a %>% add_row(.before=index2) %>% mutate("cond_site"=names(df_sites)[2]),tmp_est3a %>% add_row(.before=index3) %>% mutate("cond_site"=names(df_sites)[3])) %>% mutate(cond_site=factor(cond_site))
# # spatial sequantial estimates (parametric alpha, no Keef constraints)
# map_param(tmp_est = tmp,method = "AGG",facet_var = "cond_site")

#plot_map_param(tmp_est1=tmp_est1a,tmp_est2=tmp_est2a,tmp_est3=tmp_est3a)
```

We can observe that imposing a parametric form on $\hat{\alpha}$ that only changes with distance leads to some unexpected values of $\hat{\beta}$ close to $1$. For the AGG distribution estimates, $\hat{\mu}_{AGG}$ is the mode of the distribution whereas $\hat{\mu}$ is the median as well as the mode for the symmetric Gaussian distribution. Therefore, lower values for $\hat{\mu}_{AGG}$ suggest heavier tails for the upper tail of the distribution. This is also shown by a positive difference of $\hat{\sigma}_u-\hat{\sigma}_l$.

## New iterative approach

Try a parametric alpha decaying exponentially with distance.

```{r}
# cond_site <- find_site_index(Birmingham)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_site,],uk_sf_rot[-cond_site,]))
# newite1 <- par_est_ite(df = sims, d1j = dij, v = v, given = cond_site, N = 10, show_ite = TRUE)
# 
# cond_site <- find_site_index(Glasgow)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_site,],uk_sf_rot[-cond_site,]))
# newite2 <- par_est_ite(df = sims, d1j = dij, v = v, given = cond_site, N = 10, show_ite = TRUE)
# 
# cond_site <- find_site_index(London)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_site,],uk_sf_rot[-cond_site,]))
# newite3 <- par_est_ite(df = sims, d1j = dij, v = v, given = cond_site, N = 10, show_ite = TRUE)
```

First, we plot the iterations of parameter estimates to check convergence.

```{r}
plot_par_est_ite <- function(newite,pick_site=100) {
df <- data.frame("a"=as.numeric(newite[[1]][pick_site,]), "mu" = as.numeric(newite[[2]][pick_site,]), "sig" = as.numeric(newite[[3]][pick_site,]), "index" = 0:(ncol(newite[[1]])-1))
p1 <- ggplot(df) + geom_point(aes(x=index,y=a)) + ylab(TeX("$\\alpha$"))
p2 <- ggplot(df) + geom_point(aes(x=index,y=mu)) + ylab(TeX("$\\mu$"))
p3 <- ggplot(df) + geom_point(aes(x=index,y=sig)) + ylab(TeX("$\\sigma$"))
return(grid.arrange(p1,p2,p3,ncol=3))
}
plot_par_est_ite(newite = newite1)
```

Repeat also for Glasgow.

```{r}
plot_par_est_ite(newite = newite2,pick_site = 50)
```

and London.

```{r}
plot_par_est_ite(newite = newite3)
```

Plot also on a map.
```{r}
# index1 <- find_site_index(as.numeric(df_sites[,1]))
# index2 <- find_site_index(as.numeric(df_sites[,2]))
# index3 <- find_site_index(as.numeric(df_sites[,3]))
#                           
# tmp <- rbind(newite1 %>%  add_row(.before=index1) %>% mutate("cond_site"=names(df_sites)[1]), newite2 %>% add_row(.before=index2) %>% mutate("cond_site"=names(df_sites)[2]), newite3 %>% add_row(.before=index3) %>% mutate("cond_site"=names(df_sites)[3])) %>% mutate(cond_site=factor(cond_site))

#plot_map_param(tmp_est1 = newite1[[4]], tmp_est2 = newite2[[4]], tmp_est3 = newite3[[4]],method= "iterative_alpha",threesites = c("Bimingham","Glasgow","London"),indeces=c(find_site_index(Birmingham),find_site_index(Glasgow),find_site_index(London)))


```

## Conditioning on any random site

Currently, the analysis is conditioning on Birmingham, Glasgow and London, ordered as first 3 columns of the temperature data for an easy link.

One way would be to calculate distance from each of the site and then filter distance for the site needed, which will be faster as this distance matrix will be already saved (twice as $d_{ij}$ and $d_{ji}$ are identical ).

We find the index of the grid sites closest to Inverness, Lancaster and Newcastle to get a better idea of potential parametric forms of the parameters.

## Sequential parameter estimation: other conditioning sites

We repeat the parameter estimation method described above for three other conditioning sites: Inverness, Lancaster and Newcastle.

```{r}
# v <- 0.9
# N <- 10
# sims <- ukcp18 %>% dplyr::select(!contains("i")) %>% t() %>% as.data.frame()
# colnames(sims) <- paste0("Y",1:ncol(sims))
# # transform to Laplace margins
# sims <- as.data.frame((sims %>% apply(c(2),FUN=row_number))/(nrow(sims)+1)) %>% apply(c(1,2),FUN=unif_laplace_pit) %>% as.data.frame()
# cond_site <- find_site_index(Inverness)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_site,],uk_sf_rot[-cond_site,]))
# newite4 <- par_est_ite(df = sims, d1j = dij, v = v, given = cond_site, N = N, show_ite = TRUE)
# 
# cond_site <- find_site_index(Lancaster)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_site,],uk_sf_rot[-cond_site,]))
# newite5 <- par_est_ite(df = sims, d1j = dij, v = v, given = cond_site, N = N, show_ite = TRUE)
# 
# cond_site <- find_site_index(Newcastle)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_site,],uk_sf_rot[-cond_site,]))
# newite6 <- par_est_ite(df = sims, d1j = dij, v = v, given = cond_site, N = N, show_ite = TRUE)
```

Examine similar plots of parameter estimate iterations for a randomly picked site $j$ (set to $j=100$).

Inverness:

```{r}
plot_par_est_ite(newite = newite4)
```

Lancaster:

```{r}
plot_par_est_ite(newite = newite5)
```

Newcastle:

```{r}
plot_par_est_ite(newite = newite6)
```

Similar to the previous section, we map the parameter estimates of the final iteration.

```{r}
#plot_map_param(tmp_est1 = newite4[[4]], tmp_est2 = newite5[[4]], tmp_est3 = newite6[[4]],method= "iterative_alpha",threesites = c("Inverness","Lancaster","Newcastle"),indeces=c(find_site_index(Inverness),find_site_index(Lancaster),find_site_index(Newcastle)))
```

## Sequential parameter estimation: $3$ new sites

```{r, echo=FALSE}
map_param(tmp_est = est_all_nokeef %>% filter(cond_site %in% names(df_sites)[4:6]),method = "AGG",facet_var = "cond_site")
```

Now fit exponential to $\alpha$ estimates and find MLE for the other parameters using the sequential approach.

```{r}
# plot parameter estimates against distance and on a map
# cond_var <- find_site_index(Inverness)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_var,],uk_sf_rot[-cond_var,]))
# opt <- optim(par=c(0.01,0.1),fn=NLL_exp_norm_noise,x=tmp_est4$a,d=dij)
# tmp_est4a <- par_est(sims,v=v,given=c(cond_var),margin = "AGGsigdelta", method="sequential3", a=exp(-opt$par[1]*dij))
# 
# cond_var <- find_site_index(Lancaster)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_var,],uk_sf_rot[-cond_var,]))
# opt <- optim(par=c(0.01,0.1),fn=NLL_exp_norm_noise,x=tmp_est5$a,d=dij)
# tmp_est5a <- par_est(sims,v=v,given=c(cond_var),margin = "AGGsigdelta", method="sequential3", a=exp(-opt$par[1]*dij))
# 
# cond_var <- find_site_index(Newcastle)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_var,],uk_sf_rot[-cond_var,]))
# opt <- optim(par=c(0.01,0.1),fn=NLL_exp_norm_noise,x=tmp_est6$a,d=dij)
# tmp_est6a <- par_est(sims,v=v,given=c(cond_var),margin = "AGGsigdelta", method="sequential3",a=exp(-opt$par[1]*dij))
# 

#plot_map_param(tmp_est1=tmp_est4a,tmp_est2=tmp_est5a,tmp_est3=tmp_est6a,threesites = c("Inverness","Lancaster","Newcastle"),method="AGG",indeces=c(find_site_index(Inverness),find_site_index(Lancaster),find_site_index(Newcastle)))
```

## New sites: Cromer, Hull and Lowestoft

```{r}
# v <- 0.9
# N <- 10
# 
# cond_site <- find_site_index(Cromer)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_site,],uk_sf_rot[-cond_site,]))
# newite7 <- par_est_ite(df = sims, d1j = dij, v = v, given = cond_site, N = N, show_ite = TRUE)
# 
# cond_site <- find_site_index(Hull)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_site,],uk_sf_rot[-cond_site,]))
# newite8 <- par_est_ite(df = sims, d1j = dij, v = v, given = cond_site, N = N, show_ite = TRUE)
# 
# cond_site <- find_site_index(Lowestoft)
# dij <- as.numeric(st_distance(uk_sf_rot[cond_site,],uk_sf_rot[-cond_site,]))
# newite9 <- par_est_ite(df = sims, d1j = dij, v = v, given = cond_site, N = N, show_ite = TRUE)

#plot_map_param(tmp_est1 = newite7[[4]], tmp_est2 = newite8[[4]], tmp_est3 = newite9[[4]],method= "iterative_alpha",threesites = c("Cromer","Hull","Lowestoft"),indeces=c(find_site_index(Cromer),find_site_index(Hull),find_site_index(Lowestoft)))
```

```{r}
# # save these objects for faster knitting
# save(uk,uk_temp_sf,tmp_est1,tmp_est2,tmp_est3,tmp_est1a,tmp_est2a,tmp_est3a,tmp_est4,tmp_est5,tmp_est6,tmp_est4a,tmp_est5a,tmp_est6a,tmp_est7,tmp_est8,tmp_est9,tmp_est10,tmp_est11,tmp_est12,newite1,newite2,newite3,newite4,newite5,newite6,newite7,newite8,newite9,file = "spatialobjects.RData")

map_param(tmp_est = est_all_nokeef %>% filter(cond_site %in% names(df_sites)[7:9]),method = "AGG",facet_var = "cond_site")
```

# Explore time dependence

```{r}
# change sims depending on the value of tau and cond_site
# if tau is positive, remove tau number of rows at the end of each year
# if tau is negative, remove tau number of rows at the beginning of each year
dayshift <- c(-3:3)
shift_time <- function(sims=sims,cond_site=cond_site,tau=0) {
  if (tau==0) {
    return(sims)
  }
dayshift <- c(-3:3)
dayremove <- c(88,89,90,0,1,2,3)
dayremove[dayshift %in% (0:tau)[-1]]

daysremove_condsite <- daysremove_othersites <-  c()
daysremove_condsite <- as.numeric(sapply(1:19,function(i){append(daysremove_condsite,dayremove[dayshift %in% (0:-tau)[-1]]+90*(i-1))}))
daysremove_othersites <- as.numeric(sapply(1:19,function(i){append(daysremove_othersites,dayremove[dayshift %in% (0:tau)[-1]]+90*(i-1))}))

sims_tau <-  data.frame(matrix(ncol=ncol(sims),nrow=nrow(sims)-abs(tau)*19))
names(sims_tau) <- names(sims)
sims_tau[,cond_site] <- sims[-daysremove_condsite,cond_site]
sims_tau[,-cond_site] <- sims[-daysremove_othersites,-cond_site]
return(sims_tau)
}
```

Run for all the 12 sites.

```{r}
est_all <- data.frame("lik" = numeric(), "lika"= numeric(),"likb"= numeric(),"lik2"= numeric(),
                          "a" = numeric(), "b" = numeric(),
                          "mu" = numeric(),"mu_agg" = numeric(),
                          "sig" = numeric(),"sig_agg" = numeric(),"sigl" = numeric(),"sigu" = numeric(),
                          "delta" = numeric(),"deltal" = numeric(), "deltau" = numeric(),
                          "given" = numeric(), "res" = numeric(), "cond_site" = character(), "tau" = numeric())
for (i in 1:ncol(df_sites)) {
  cond_site <- find_site_index(as.numeric(df_sites[,i]))
  for (j in 1:length(dayshift)) {
    sims_tau <- shift_time(sims=sims,cond_site=cond_site,tau=dayshift[j])
    est_all <- rbind(est_all,par_est(df=sims_tau,v=v,given=cond_site,margin = "AGGsigdelta", method="sequential2",keef_constraints = c(1,2)) %>% add_row(.before=cond_site) %>%  mutate(cond_site=names(df_sites[i]),tau=as.character(dayshift[j])))
  }
}
```

Map and save for all sites.

```{r}
# est_all <- est_all %>% mutate(tau=factor(as.character(tau),levels = as.character(-3:3)))
# save(est_all,file="est_all.RData")

load("est_all.RData")
# condmodel_params <- c("a","b","mu","sig","muagg","sigl","sigu","sigdiff","deltal","deltau","deltadiff")
# condmodel_params <- c("a","b","mu","sig")
# for (i in 1:ncol(df_sites)) {
# tau_site_map <- map_param(tmp_est=est_all %>% filter(cond_site==names(df_sites)[i]),method="AGG",facet_var = "tau",title_map = names(df_sites)[i])
#   for (j in 1:length(condmodel_params)) {
#     tmap_save(tau_site_map[[j]],filename=paste0("../Documents/est_all_keef/tau_",names(df_sites[i]),"_map_",j,"_",condmodel_params[j],".png"),width=15,height=4.5)
#   }
# }
```

Save max over the time period and which day it is.

```{r}
# create two new columns with max and which.max across different tau
# n_sites <- length(unique(est_all$res[!is.na(est_all$res)]))
# condmodel_params <- c("a","b","mu","sig")
# est_all_m <- as.data.frame(matrix(ncol=length(condmodel_params)*2+2,nrow=0))
# names(est_all_m) <- c("index","a","a_tau","b","b_tau","mu","mu_tau","sig","sig_tau")
# for (i in 1:ncol(df_sites)) {
#   est_all_max <- data.frame("index"=1:n_sites)
#   for (k in 1:length(condmodel_params))  {
#     max_map <- max_time <- rep(NA,n_sites)
#     for (j in 1:n_sites) {
#       if (j==find_site_index(as.numeric(df_sites[,i]))) {
#         max_map[j] <- max_time[j] <- NA
#       } else {
#       max_map[j] <- est_all %>% filter(cond_site==names(df_sites[i]),res==j) %>% dplyr::select(condmodel_params[k]) %>%  pull() %>% max()
#       max_time[j] <- dayshift[est_all %>% filter(cond_site==names(df_sites[i]),res==j) %>% dplyr::select(condmodel_params[k]) %>%  pull() %>% which.max()]
#       }
#     }
#     est_all_max <- cbind(est_all_max,data.frame(max_map, max_time))
#    names(est_all_max)[c(ncol(est_all_max)-1,ncol(est_all_max))]<- c(condmodel_params[k],paste0(condmodel_params[k],"_tau"))
#   }
#   est_all_m[(n_sites*(i-1)+1):(n_sites*i),] <- est_all_max %>% mutate(cond_site=names(df_sites)[i])
# }
# names(est_all_m)[ncol(est_all_m)] <- "cond_site"
# est_all_m <- est_all_m %>% mutate(cond_site=factor(cond_site,levels=names(df_sites))) %>% mutate(a_tau = factor(as.character(a_tau),levels=as.character(dayshift)))
# # map maximum estimates and the time
# tmap_save(map_param(tmp_est=est_all_m,method="max_tau",facet_var = "cond_site")[[1]],filename="../Documents/est_all_keef/a_max_tau.png",width=6,height=10)
# 
# tmap_save(map_param(tmp_est=est_all_m,method="max_tau",facet_var = "cond_site")[[2]],filename="../Documents/est_all_keef/a_max_whichtau.png",width=6,height=10)
# run rs.restartR() if [[2]] produces lazy-database error
```

## Explore high values of $\beta$

```{r}
cond_site1 <- find_site_index(as.numeric(df_sites[,10])) # column 10 "Truro"
res_site <- find_site_index(as.numeric(df_sites[,9])) #column 9 "Lowestoft"
tmp <- est_all %>% filter(cond_site==names(df_sites)[10],res==res_site) %>% select(a,b,res,cond_site,tau)
tmp
```

Scatterplot of $(Y_{172},Y_{Truro}| Y_{Truro}>v$.

```{r}
sims_tau <- shift_time(sims=sims,cond_site=cond_site1,tau=dayshift[1]) %>% select(all_of(c(cond_site1,res_site))) 
names(sims_tau) <- c("Y1","Y2")
pe <- par_est(df=sims_tau,v=v,given=1,,margin = "AGGsigdelta", method="sequential2",keef_constraints = c(1,2)) 
pe # check that this is same as above
ggplot(sims_tau) + geom_point(aes(x=Y1,y=Y2)) # laplace margins look fine
Y_given1extreme <- sims_tau %>% filter(sims_tau[,1]>quantile(sims_tau[,1],v))
ggplot(Y_given1extreme) + geom_point(aes(x=Y1,y=Y2)) # laplace margins look fine
ggplot(sims_tau) + geom_density(aes(x=Y2)) # Y1 and Y2 have Laplace margins
```

Explore how a scatterplot varies for different $\tau$.

```{r}
Y <- sims_tau %>% mutate("tau"=dayshift[1])
Y_given1extreme <- sims_tau %>% filter(sims_tau[,1]>quantile(sims_tau[,1],v)) %>%  mutate("tau"=dayshift[1])
for (i in dayshift[2:7]) {
 sims_tau <- shift_time(sims=sims,cond_site=cond_site1,tau=i) %>% select(all_of(c(cond_site1,res_site))) 
names(sims_tau) <- c("Y1","Y2")
 Y <- rbind(Y,sims_tau %>% mutate("tau"=i))
 Y_given1extreme <- rbind(Y_given1extreme,sims_tau %>% filter(sims_tau[,1]>quantile(sims_tau[,1],v)) %>%  mutate("tau"=i))
}
Y <- Y %>% mutate(tau=factor(tau))
Y_given1extreme <- Y_given1extreme %>% mutate(tau=factor(tau))
ggplot(Y) + geom_point(aes(x=Y1,y=Y2)) + facet_wrap(~tau) 
ggplot(Y_given1extreme) + geom_point(aes(x=Y1,y=Y2))+ facet_wrap(~tau,ncol=7)  

```

Explore quantiles of the data (on the Laplace scale).

```{r}
cond_sites <- c("Birmingham","Inverness","Cromer")
tmp <- est_all %>% filter(cond_site %in% cond_sites)
x0999 <- unif_laplace_pit(0.999)
q025 <- q075 <- numeric()
for (i in 1:nrow(tmp)) {
    # filter value of a and b
  a <- as.numeric(tmp[i,5])
  b <- as.numeric(tmp[i,6])
  if (is.na(a)) {q025[i] <- q075[i] <- NA} else {
  # find residual variable and cond.variable
  cond_site. <- find_site_index(as.numeric(df_sites[,tmp$cond_site[i]]))
  res_site <- tmp$res[i]
  # calculate Y1 and Yj
  sims_tau <- shift_time(sims=sims,cond_site=cond_site.,tau=as.numeric(as.character(est_all$tau[i]))) %>% select(all_of(c(cond_site.,res_site)))
  names(sims_tau) <- c("Y1","Y2")
  Y1_Y2 <- sims_tau %>% filter(sims_tau[,1]>quantile(sims_tau[,1],v))
  Y1 <- as.numeric(Y1_Y2[,1])
  Y2 <- as.numeric(Y1_Y2[,2])
  # calculate observed residuals
  z <- (Y2-a*Y1)/(Y1^b)
  # calculate q025 and q075
  q025[i] <- a*x0999+x0999^b*quantile(z,0.25)
  q075[i] <- a*x0999+x0999^b*quantile(z,0.75)
  }
}

# join and map
tmp <- tmp %>% mutate(q025,q075) %>%  pivot_longer(,cols=c(q025,q075),names_to = "q") %>% arrange(q) %>% mutate(q=factor(q)) %>% mutate(tau=factor(as.character(tau),levels=unique(as.character(tmp$tau))))

rl025 <- sapply(1:length(q025),function(i){1/(1-pgnorm(q=q025[i]))})
rl075 <- sapply(1:length(q075),function(i){1/(1-pgnorm(q=q075[i]))})
tmp <- tmp %>% mutate(rl=c(rl025,rl075))
tmp025 <- tmp %>% filter(q=="q025")
tmp075 <- tmp %>% filter(q=="q075")

# save for all cond_sites
# for (i in 1:length(cond_sites)) {
# tmap_save(map_param(tmp_est=tmp025 %>% filter(cond_site==cond_sites[i]),method = "q", facet_var = c("q","tau"),title_map = cond_sites[i]),filename=paste0("../Documents/est_all_keef/q025_tau_",cond_sites[i],".png"),width=12,height=4.5)
# tmap_save(map_param(tmp_est=tmp075 %>% filter(cond_site==cond_sites[i]),method = "q", facet_var = c("q","tau"),title_map = cond_sites[i]),filename=paste0("../Documents/est_all_keef/q075_tau_",cond_sites[i],".png"),width=12,height=4.5)
# }

tmap_save(map_param(tmp_est=tmp025,method = "q", facet_var = c("cond_site","tau"),title_map = TeX("$p=0.25$")),filename=paste0("../Documents/est_all_keef/q025_tau.png"),width=12,height=9.5)
tmap_save(map_param(tmp_est=tmp025,method = "rl", facet_var = c("cond_site","tau"),title_map = TeX("$p=0.25$")),filename=paste0("../Documents/est_all_keef/rl025_tau.png"),width=12,height=9.5)

tmap_save(map_param(tmp_est=tmp075,method = "q", facet_var = c("cond_site","tau"),title_map = TeX("$p=0.75$")),filename=paste0("../Documents/est_all_keef/q075_tau.png"),width=12,height=9.5)
tmap_save(map_param(tmp_est=tmp075,method = "rl", facet_var = c("cond_site","tau"),title_map = TeX("$p=0.75$")),filename=paste0("../Documents/est_all_keef/rl075_tau.png"),width=12,height=9.5)

# for (i in 1:length(cond_sites)) {
# tmap_save(map_param(tmp_est=tmp025 %>% filter(cond_site==cond_sites[i]),method = "q", facet_var = c("rl","tau"),title_map = cond_sites[i]),filename=paste0("../Documents/est_all_keef/rl025_tau_",cond_sites[i],".png"),width=12,height=4.5)
#   tmap_save(map_param(tmp_est=tmp075 %>% filter(cond_site==cond_sites[i]),method = "q", facet_var = c("rl","tau"),title_map = cond_sites[i]),filename=paste0("../Documents/est_all_keef/rl075_tau_",cond_sites[i],".png"),width=12,height=4.5)
# }

```

